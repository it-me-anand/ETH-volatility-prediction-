{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e97cc-bc87-4eb6-967f-63967981b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split,TimeSeriesSplit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "train= True      # amke false for prediction\n",
    "\n",
    "def clean(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df =df.set_index('timestamp')\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    low , high = df['mid_price'].quantile([0.02,0.98])   # removed outliers \n",
    "    df= df[df['mid_price'].between(low,high)]  \n",
    "    return df\n",
    "\n",
    "def realized_volatility(series,n):\n",
    "    return series.ewm(span=n).std()\n",
    "\n",
    "def features(df):\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    X['wap1']= (df['bid_price1']*df['ask_volume1'] + df['ask_price1']*df['bid_volume1'])/(df['bid_volume1']+df['ask_volume1'])\n",
    "    X['wap2']= (df['bid_price2']*df['ask_volume2'] + df['ask_price2']*df['bid_volume2'])/(df['bid_volume2']+df['ask_volume2'])\n",
    "    X['wap3']= (df['bid_price3']*df['ask_volume3'] + df['ask_price3']*df['bid_volume3'])/(df['bid_volume3']+df['ask_volume3'])\n",
    "    X['wap4']= (df['bid_price4']*df['ask_volume4'] + df['ask_price4']*df['bid_volume4'])/(df['bid_volume4']+df['ask_volume4'])\n",
    "    X['wap5']= (df['bid_price5']*df['ask_volume5'] + df['ask_price5']*df['bid_volume5'])/(df['bid_volume5']+df['ask_volume5'])\n",
    "    X['mid_return'] = df['mid_price'].diff()\n",
    "    X['spread_bps'] = (df['ask_price1'] - df['bid_price1']) / df['mid_price'] * 10000\n",
    "    for n in [10,20,50,100,200,300,450,600]:\n",
    "        for i in range(1,6):\n",
    "            X[f'wap{i}_rol{n}'] = X[f'wap{i}'].ewm(span=n).mean()\n",
    "            X[f'rv_wap{i}_rol{n}'] = X[f'wap{i}'].ewm(span=n).std()\n",
    "    X['log_return1'] = X['wap1'].diff()\n",
    "    X['log_return2'] =  (X['wap2']).diff()\n",
    "    X['log_return3'] =  (X['wap3']).diff()\n",
    "    X['log_return4'] =  (X['wap4']).diff()\n",
    "    X['log_return5'] =  (X['wap5']).diff()\n",
    "    X['log_return_ask1'] = (df['ask_price1']).diff()\n",
    "    X['log_return_ask2'] = (df['ask_price2']).diff()\n",
    "    X['log_return_bid1'] = (df['bid_price1']).diff()\n",
    "    X['log_return_bid2'] = (df['bid_price2']).diff()\n",
    "    for col in X.columns:\n",
    "        if 'log' in col:\n",
    "            for n in [10,20,50,100,200,300,450,600]:\n",
    "                X[f'rv_{col}_{n}']= realized_volatility(X[col],n)\n",
    "    X['wa_bal1'] = np.abs(X['wap1']-X['wap2'])\n",
    "    X['bid_spread1'] = df['bid_price1'] - df['bid_price2']\n",
    "    X['bid_spread2'] =df['bid_price2'] - df['bid_price3']\n",
    "    X['ask_spread1'] = df['ask_price1'] - df['ask_price2']\n",
    "    X['ask_spread2'] = df['ask_price2'] - df['ask_price3']\n",
    "    X['total_ask_volume'] = df['ask_volume1'] + df['ask_volume2'] + df['ask_volume3'] + df['ask_volume4'] + df['ask_volume5'] \n",
    "    X['total_bid_volume'] = df['bid_volume1'] + df['bid_volume2'] + df['bid_volume3'] + df['bid_volume4'] + df['bid_volume5'] \n",
    "    X['total_volume'] = X['total_ask_volume']+X['total_bid_volume']\n",
    "    X['volume_imbalance'] = X['total_ask_volume'] - X['total_bid_volume']\n",
    "    X['vol_ratio'] = X['total_bid_volume']/X['total_ask_volume']\n",
    "    X['order_flow_pressure'] = (X['total_bid_volume']-X['total_ask_volume'])/(X['total_volume']+1)\n",
    "    for n in [10,20,50,100,200,300,450,600]:\n",
    "        X[f'ofp_rol_{n}']= X['order_flow_pressure'].ewm(span=n).mean()\n",
    "        X[f'ofp_rol_diff_{n}'] = X[f'ofp_rol_{n}'].diff()\n",
    "        X[f'rv_mid_return_{n}']   =X['mid_return'].ewm(span=n).std()\n",
    "    for n in range(1,6):\n",
    "        X[f'vol_imb_{n}'] = (df[f'bid_volume{n}'] - df[f'ask_volume{n}'] ) / (df[f'bid_volume{n}'] + df[f'ask_volume{n}'])\n",
    "        X[f'toxic_flow{n}'] = -(X[f'vol_imb_{n}']* X[f'log_return{n}'])\n",
    "    #for func in ['count','sum','skew','kurt']:\n",
    "    \n",
    "    return X\n",
    "# custom evaluation metric for the validating the model\n",
    "def pearson_metric(y_true, y_pred):  \n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "pearson_scorer = make_scorer(pearson_metric, greater_is_better=True) \n",
    "\n",
    "def train(X,y,tscv):\n",
    "    model = lgb.LGBMRegressor(\n",
    "    #device='GPU',    use GPU if gpu available\n",
    "    objective='regression',\n",
    "    verbosity=-1,\n",
    "    n_jobs=-1,\n",
    "    #random_state=42\n",
    "    )\n",
    "\n",
    "    cv_search_space = {\n",
    "    'n_estimators': np.arange(100, 3000, 100),\n",
    "    'max_depth': np.arange(2, 20, 2),\n",
    "    'num_leaves': np.arange(20, 100, 20),\n",
    "    'min_child_samples': np.arange(10, 1000, 50),\n",
    "    'max_bin': np.arange(10, 200, 5),\n",
    "    'reg_alpha': np.linspace(0.01, 5.0, 5),\n",
    "    'reg_lambda': np.linspace(0.01, 5.0, 5),\n",
    "    'colsample_bytree': np.linspace(0.1, 0.5, 5),\n",
    "    'min_child_weight': np.linspace(0.01, 10, 2),\n",
    "    'subsample': np.linspace(0.01, 1, 2),\n",
    "    }\n",
    "\n",
    "    rand_cv = RandomizedSearchCV(\n",
    "    estimator=model, \n",
    "    param_distributions=cv_search_space,\n",
    "    scoring=pearson_scorer,\n",
    "    n_iter=5,\n",
    "    verbose=3,\n",
    "    cv=tscv,\n",
    "    n_jobs=1\n",
    "    )\n",
    "\n",
    "    rand_cv.fit(X, y)  # No early_stopping_rounds here\n",
    "    print(f\"Best ROC AUC: {rand_cv.best_score_:.4f}\")\n",
    "    print(f\"Best params: {rand_cv.best_params_}\")\n",
    "    model = rand_cv.best_estimator_\n",
    "    return model\n",
    "\n",
    "train=pd.read_csv(\"/kaggle/input/gq-implied-volatility-forecasting/train/ETH.csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/gq-implied-volatility-forecasting/test/ETH.csv\")\n",
    "sub=pd.read_csv(\"/kaggle/input/gq-implied-volatility-forecasting/submission.csv\")\n",
    "train =clean(train)\n",
    "X = features(train)\n",
    "y= train['label']\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = training(X,y,tscv)\n",
    "test = features(test)\n",
    "if set(test)==set(X):\n",
    "    print('model ready to predict')\n",
    "    sub['labels'] = model.predict(test)\n",
    "else:\n",
    "    print('check features for error')\n",
    "    \n",
    "sub.to_csv(\"sub.csv\", index=False)\n",
    "print('file is ready to be submitted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
